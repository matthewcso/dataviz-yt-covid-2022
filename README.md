
### Important data files
A copy of aggregated_data.csv and aggregated_coded_data.csv can be found in the subfolder outputs. They may not be fully up-to-date if the coding sheets have changed. (check git for last update date)

### Downloading Files:
#### Manually downloading:
- Manually download the files from (here) [https://drive.google.com/drive/u/2/folders/15CSJvK4uRwZFu_GNZvsAktKIy0gl9-x9]. 

#### Downloading via API: 
- Follow the steps found (here) [https://developers.google.com/workspace/guides/create-project].

- Open (Google Cloud Console) [https://console.cloud.google.com/]. Navigate to the left bar, create a new project. Click Enable APIs and Services to view the API library, then select and enable Google Drive API. 
- Use the dropdown bar on the left to select Credentials. Download the OAuth2.0 client configuration by clicking the download button on the right of the created OAuth client ID. Rename the file to credentials/credentials.json (in drive_loading/).

- Run drive_loading.py. (python3 drive_loading.py)
	- On your first run, Python will "Please visit this URL to authorize this application:". If this happens, follow the link, ignore warnings about no verification and proceed. Grant your project permission. Confirm your choice. 
- Subsequent runs do not need manual verification if token.pickle exists in credentials.

#### Information about drive_loading.py
By default, the parent folder is (Sophie's folder) [https://drive.google.com/drive/u/2/folders/15CSJvK4uRwZFu_GNZvsAktKIy0gl9-x9] (the parent_folder parameter in the script is the last string of letters and numbers, 15CSJvK4uRwZFu_GNZvsAktKIy0gl9-x9).The code will automatically update the sheets upon running drive_loading.py. The result here is a directory full of weekly csv files, located in drive_files.

### Making an aggregated coding sheet
Install requirements from requirements.txt. (pip3 install -r requirements.txt)
Run aggregation.py to generate
* aggregated_data.csv â€“ 
* aggregated_coded_data.csv. This depends on several .tsv files located in this directory. If changing the .tsv files, make sure that they're actually valid files.(if you're not sure, save a Slides/Excel/LibreOffice spreadsheet in TSV format!!)

(JD): The data table sent out to the lab can be generated by running the Makefile in this folder, if using Linux.

### Sample commands to get started
This assumes that you want to download via API, and that you've already created credentials/credentials.json. Tested on Windows Subsystem for Linux. Run the commands in order.
- pip3 install -r requirements.txt
- python3 drive_loading.py
- python3 aggregation.py

### Visualization (Old! JD is working on upgrades.)
The old visualization.R script has been broken into multiple standalone scripts (effectively was several separate scripts in the same file). 

Note that there is lots of repeated code in these scripts overall. I might refactor this in the future if the need arises. For now, though: if you make a change in one file, it won't affect anything else.

Run:
- counts_by_source.R
- counts_by_theme.R
- prevention_timeseries.R
- source_timeseries.R
- stacked_barplots.R
- theme_timeseries.R
- view_and_count_timeseries.R

If there's an issue with these files, please email me ASAP. som5@mcmaster.ca, or somatthewc@gmail.com if I don't respond with the first email (the first email will eventually stop working, and I don't know when you'll read this message in the future)

